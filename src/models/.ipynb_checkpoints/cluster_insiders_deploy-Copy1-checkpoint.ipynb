{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631f761f",
   "metadata": {},
   "source": [
    "# 0.0 Imports and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc613ed6",
   "metadata": {},
   "source": [
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3357e234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:15:35.930180Z",
     "start_time": "2024-03-16T23:14:29.817868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import warnings\n",
    "import re\n",
    "import s3fs\n",
    "import awswrangler as wr\n",
    "\n",
    "import umap.umap_ as umap\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn import cluster       as c\n",
    "from sklearn import metrics       as m\n",
    "from sklearn import ensemble      as en\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import decomposition as dd\n",
    "from sklearn import manifold      as mn\n",
    "from sklearn import mixture       as mx\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7585ba-26f4-44e3-b7c7-79f52e39596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # acesso ao S3\n",
    "# os.environ.get('arn:aws:kms:us-east-1:679236183272:key/6042566d-1d31-4e13-a535-d44fe4d7bf8b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee09430",
   "metadata": {},
   "source": [
    "## 0.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd450107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.238944Z",
     "start_time": "2024-03-16T23:15:35.935189Z"
    }
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\s3fs\\core.py:113\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[1;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\aiobotocore\\client.py:408\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    407\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (403) when calling the HeadObject operation: Forbidden",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3://insiders-cds-bhmr240324/online_retail.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# path_csv_s3 = 's3://insiders-cds-bhmr240324/Ecommerce.csv'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# wr.config.aws_profile = 'default' # define o perfil padrão logado na AWS\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# wr.config.region = 'us-east-1'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# df = wr.s3.read_excel(path)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv(path_csv_s3, encoding = 'iso8859-1')\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\pandas\\io\\common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\pandas\\io\\common.py:429\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    427\u001b[0m             storage_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(storage_options)\n\u001b[0;32m    428\u001b[0m             storage_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m         file_obj \u001b[38;5;241m=\u001b[39m \u001b[43mfsspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    434\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mfile_obj,\n\u001b[0;32m    435\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    438\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[0;32m    439\u001b[0m     )\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m storage_options:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\core.py:135\u001b[0m, in \u001b[0;36mOpenFile.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Materialise this as a real open file without context\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    The OpenFile object should be explicitly closed to avoid enclosed file\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    instances persisting. You must, therefore, keep a reference to the OpenFile\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    during the life of the file-like it generates.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\core.py:103\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    101\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 103\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobjects \u001b[38;5;241m=\u001b[39m [f]\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\spec.py:1293\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1293\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[0;32m   1294\u001b[0m         path,\n\u001b[0;32m   1295\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   1296\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[0;32m   1297\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[0;32m   1298\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[0;32m   1299\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1300\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\s3fs\\core.py:685\u001b[0m, in \u001b[0;36mS3FileSystem._open\u001b[1;34m(self, path, mode, block_size, acl, version_id, fill_cache, cache_type, autocommit, size, requester_pays, cache_options, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     cache_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_cache_type\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mS3File\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43macl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_additional_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequester_pays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequester_pays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\s3fs\\core.py:2179\u001b[0m, in \u001b[0;36mS3File.__init__\u001b[1;34m(self, s3, path, mode, block_size, acl, version_id, fill_cache, s3_additional_kwargs, autocommit, cache_type, requester_pays, cache_options, size)\u001b[0m\n\u001b[0;32m   2177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetails \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39minfo(path)\n\u001b[0;32m   2178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetails\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2179\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2187\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs  \u001b[38;5;66;03m# compatibility\u001b[39;00m\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;66;03m# when not using autocommit we want to have transactional state to manage\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\spec.py:1651\u001b[0m, in \u001b[0;36mAbstractBufferedFile.__init__\u001b[1;34m(self, fs, path, mode, block_size, autocommit, cache_type, cache_options, size, **kwargs)\u001b[0m\n\u001b[0;32m   1649\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1651\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetails\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m caches[cache_type](\n\u001b[0;32m   1653\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_range, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcache_options\n\u001b[0;32m   1654\u001b[0m     )\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\spec.py:1664\u001b[0m, in \u001b[0;36mAbstractBufferedFile.details\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetails\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_details \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1664\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_details\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\fsspec\\asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[1;34m(event, coro, result, timeout)\u001b[0m\n\u001b[0;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\s3fs\\core.py:1371\u001b[0m, in \u001b[0;36mS3FileSystem._info\u001b[1;34m(self, path, bucket, key, refresh, version_id)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[0;32m   1372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[0;32m   1374\u001b[0m             Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[0;32m   1375\u001b[0m             Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[0;32m   1376\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id),\n\u001b[0;32m   1377\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[0;32m   1378\u001b[0m         )\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m   1380\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1388\u001b[0m         }\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\s3fs\\core.py:362\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[1;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, akwarglist, kw2)\n\u001b[0;32m    361\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[0;32m    363\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[0;32m    364\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ds_clusterizacao\\lib\\site-packages\\s3fs\\core.py:142\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[1;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[0;32m    140\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m    141\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[1;31mPermissionError\u001b[0m: Forbidden"
     ]
    }
   ],
   "source": [
    "# df = pd.read_excel('C:/Users/micro/Desktop/repos/3_ciclo_intermediario/3_ds_em_clusterizacao/data_original/online_retail.xlsx')\n",
    "\n",
    "path = 's3://insiders-cds-bhmr240324/online_retail.xlsx'\n",
    "# path_csv_s3 = 's3://insiders-cds-bhmr240324/Ecommerce.csv'\n",
    "\n",
    "# wr.config.aws_profile = 'default' # define o perfil padrão logado na AWS\n",
    "# wr.config.region = 'us-east-1'\n",
    "# df = wr.s3.read_excel(path)\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "# df = pd.read_csv(path_csv_s3, encoding = 'iso8859-1')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20c03e",
   "metadata": {},
   "source": [
    "# 1.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8eb10",
   "metadata": {},
   "source": [
    "## 1.1 Initial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c9100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.270009Z",
     "start_time": "2024-03-16T23:17:02.242969Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ee63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.347812Z",
     "start_time": "2024-03-16T23:17:02.271946Z"
    }
   },
   "outputs": [],
   "source": [
    "# renomeando colunas\n",
    "cols_new = ['invoice_no','stock_code','description','quantity','invoice_date','unit_price','customer_id','country']\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddfab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.705012Z",
     "start_time": "2024-03-16T23:17:02.350745Z"
    }
   },
   "outputs": [],
   "source": [
    "# alterando os tipos dos dados\n",
    "df1['invoice_date'] = pd.to_datetime(df1['invoice_date'], format = '%d-%b-%y')\n",
    "df1['invoice_no'] = df1['invoice_no'].astype(str)\n",
    "df1['stock_code'] = df1['stock_code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500da1a",
   "metadata": {},
   "source": [
    "## 1.2 Replacing NaN Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c989383",
   "metadata": {},
   "source": [
    "### Second Cicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a04c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.799037Z",
     "start_time": "2024-03-16T23:17:02.706995Z"
    }
   },
   "outputs": [],
   "source": [
    "# checando clientes sem id\n",
    "df_missing = df1.loc[df1['customer_id'].isna(), :]\n",
    "df_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c85cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.845994Z",
     "start_time": "2024-03-16T23:17:02.802019Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropando transações duplicadas para que cada transação represente um único cliente\n",
    "# essa solução não é a ideal, visto que um mesmo cliente pode realizar várias transações\n",
    "# porém, como não temos a identificação destes clientes, é uma solução plausível para este ciclo de projeto\n",
    "df_backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "df_backup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2b336",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:02.954716Z",
     "start_time": "2024-03-16T23:17:02.848997Z"
    }
   },
   "outputs": [],
   "source": [
    "# substituindo os valores faltantes dos clientes por um número muito alto, para ficar fácil de diferenciar\n",
    "# cada cliente será representado pelo id do cliente anterior + 1, para que não haja nenhum cliente repetido\n",
    "df_backup['customer_id'] = np.arange(19000, 19000+len(df_backup), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00380b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:03.265972Z",
     "start_time": "2024-03-16T23:17:02.959648Z"
    }
   },
   "outputs": [],
   "source": [
    "# unindo o dataset original com o dataset dos clientes NaNs preenchido\n",
    "df1 = pd.merge(df1, df_backup, on = 'invoice_no', how = 'left')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49300bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:03.296972Z",
     "start_time": "2024-03-16T23:17:03.268952Z"
    }
   },
   "outputs": [],
   "source": [
    "# unindo o id do cliente que for igual nos 2 datasets em uma nova coluna\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b42fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:03.420948Z",
     "start_time": "2024-03-16T23:17:03.299951Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropando as colunas extras\n",
    "df1 = df1.drop(columns = ['customer_id_x', 'customer_id_y'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d20c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:03.498729Z",
     "start_time": "2024-03-16T23:17:03.423950Z"
    }
   },
   "outputs": [],
   "source": [
    "# alterando os clientes de float para int\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764700ac",
   "metadata": {},
   "source": [
    "# 2.0 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b32b39",
   "metadata": {},
   "source": [
    "## 2.1 Checking Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f41037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:03.685198Z",
     "start_time": "2024-03-16T23:17:03.501666Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0430ec",
   "metadata": {},
   "source": [
    "## 2.3 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad82b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.026209Z",
     "start_time": "2024-03-16T23:17:03.688205Z"
    }
   },
   "outputs": [],
   "source": [
    "# removendo preços nulos e quase nulos\n",
    "df2 = df2.loc[df2['unit_price'] >= 0.04, :]\n",
    "\n",
    "# removendo produtos com códigos que não representam compras\n",
    "df2 = df2[~df2['stock_code'].isin(['POST','D','DOT','M','S','AMAZONFEE','m','DCGSSBOY','DCGSSGIRL','PADS','B','CRUK'])]\n",
    "\n",
    "# removendo a coluna description\n",
    "df2 = df2.drop(columns = 'description', axis = 1)\n",
    "\n",
    "# removendo clientes de países não específicados\n",
    "# foi escolhido remover estes clientes por representarem uma quantidade muito baixa de clientes em relação ao todo\n",
    "df2 = df2[~df2['country'].isin(['European Community','Unspecified'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6b53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.057209Z",
     "start_time": "2024-03-16T23:17:04.029196Z"
    }
   },
   "outputs": [],
   "source": [
    "# cliente com compra/devolução estranha (valor muito alto/outlier)\n",
    "df2_bad_users = df2[df2['customer_id'] == 16446]\n",
    "df2_bad_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c6677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.211007Z",
     "start_time": "2024-03-16T23:17:04.060197Z"
    }
   },
   "outputs": [],
   "source": [
    "# removendo maus usuários (cliente com comportamento estranho)\n",
    "df2 = df2[~df2['customer_id'].isin([16446])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca73c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.303677Z",
     "start_time": "2024-03-16T23:17:04.212965Z"
    }
   },
   "outputs": [],
   "source": [
    "# criando dataframes de devoluções e de compras para avaliar as compras e as devoluções posteriormente na EDA\n",
    "df2_returns = df2.loc[df2['quantity'] < 0, :]\n",
    "df2_purchases = df2.loc[df2['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff9517",
   "metadata": {},
   "source": [
    "# 3.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47147b",
   "metadata": {},
   "source": [
    "## 3.1 Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ffb9db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.397372Z",
     "start_time": "2024-03-16T23:17:04.306618Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011d3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.507255Z",
     "start_time": "2024-03-16T23:17:04.400355Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove possíveis linhas duplicadas\n",
    "df_ref = df3.drop(['invoice_no','stock_code','quantity','invoice_date','unit_price','country'], axis = 1).drop_duplicates(ignore_index = True)\n",
    "df_ref.shape # verifica a quantidade de linhas remanescentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bc5c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.616495Z",
     "start_time": "2024-03-16T23:17:04.509262Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9899ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.740215Z",
     "start_time": "2024-03-16T23:17:04.619506Z"
    }
   },
   "outputs": [],
   "source": [
    "# faturamento\n",
    "df2['gross_revenue'] = df2['quantity']*df2['unit_price']\n",
    "\n",
    "# monetary\n",
    "df_monetary = df2[['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge(df_ref, df_monetary, on = 'customer_id', how = 'left')\n",
    "\n",
    "# verifica se algum cliente do dataframe de referência não tem correspondente no dataframe monetary\n",
    "# se isso acontecesse, as linhas da coluna 'gross_revenue' sem clientes correspondentes iriam ser preenchidas com NaN\n",
    "print(df_ref.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a529845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:04.849502Z",
     "start_time": "2024-03-16T23:17:04.743154Z"
    }
   },
   "outputs": [],
   "source": [
    "# compra mais recente de cada cliente\n",
    "df_recency = df2_purchases[['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index()\n",
    "\n",
    "# data da compra mais recente no geral - data da compra mais recente de cada cliente\n",
    "df_recency['recency_days'] = (df2_purchases['invoice_date'].max() - df_recency['invoice_date']).dt.days\n",
    "\n",
    "# invertendo a data da recência, pois o modelo entende que quanto maior o valor, melhor\n",
    "df_recency['recency_days'] = df_recency['recency_days'].apply(lambda x: 1/x if x != 0 else 1)\n",
    "\n",
    "# merge\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge(df_ref, df_recency, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613421c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:05.005873Z",
     "start_time": "2024-03-16T23:17:04.852464Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantidade de transações por cliente\n",
    "df_qt_invoices = df2_purchases[['customer_id', 'invoice_no']].drop_duplicates().groupby('customer_id').count().reset_index()\n",
    "df_qt_invoices = df_qt_invoices.rename(columns = {'invoice_no': 'qt_invoices'})\n",
    "\n",
    "# drop_duplicates: é necessário, pois ao selecionar o id da compra e o id cliente aparecem linhas repetidas.\n",
    "df_ref = pd.merge(df_ref, df_qt_invoices, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5f759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:05.130145Z",
     "start_time": "2024-03-16T23:17:05.007860Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantidade de produtos únicos comprados por cliente\n",
    "df_qt_products = df2_purchases[['customer_id', 'stock_code']].groupby('customer_id').count().reset_index()\n",
    "df_qt_products = df_qt_products.rename(columns = {'stock_code': 'qt_products'})\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_qt_products, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70795535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:05.177299Z",
     "start_time": "2024-03-16T23:17:05.132150Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantidade de itens totais comprados por cliente\n",
    "df_qt_items = df2[['customer_id', 'quantity']].groupby('customer_id').sum().reset_index()\n",
    "df_qt_items = df_qt_items.rename(columns = {'quantity': 'qt_items'})\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_qt_items, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82e1e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:05.270500Z",
     "start_time": "2024-03-16T23:17:05.180237Z"
    }
   },
   "outputs": [],
   "source": [
    "# ticket médio por cliente\n",
    "df_avg_ticket = df2[['customer_id', 'gross_revenue']].groupby('customer_id').mean().reset_index()\n",
    "df_avg_ticket = df_avg_ticket.rename(columns = {'gross_revenue': 'avg_ticket'})\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_avg_ticket, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952fddd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:05.517995Z",
     "start_time": "2024-03-16T23:17:05.278453Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantidade de devoluções por cliente\n",
    "df_returns = df2_returns[['customer_id','quantity']].groupby('customer_id').sum().reset_index()\n",
    "df_returns = df_returns.rename(columns = {'quantity': 'qt_returns'})\n",
    "\n",
    "# multiplica por -1, pois as quantidades são negativas\n",
    "df_returns['qt_returns'] = df_returns['qt_returns'] * -1\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_returns, how = 'left', on = 'customer_id' )\n",
    "\n",
    "# caso a quantidade de returns for vazia, preenche a linha com 0 devoluções\n",
    "df_ref.loc[df_ref['qt_returns'].isna(),'qt_returns'] = 0\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a4187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:06.950986Z",
     "start_time": "2024-03-16T23:17:05.520989Z"
    }
   },
   "outputs": [],
   "source": [
    "# data da primeira compra - data da última compra\n",
    "df_aux = df2_purchases[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates().groupby('customer_id')\n",
    "df_aux = df_aux.agg(max_ = ('invoice_date', 'max'), min_ = ('invoice_date', 'min'), days_= ('invoice_date', lambda x: ((x.max() - x.min()).days) + 1), buy_ = ('invoice_no', 'count'))\n",
    "# precisa somar 1, pois esta diferença entre as datas irá no denominador quando calcular a frequência\n",
    "# se houve só uma compra, a diferença entre as datas é 0\n",
    "# logo, se não somar 1, será feita uma divisão por 0 e ocorrerá uma indeterminação\n",
    "df_aux = df_aux.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb77363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:06.966987Z",
     "start_time": "2024-03-16T23:17:06.953985Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3a732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.152279Z",
     "start_time": "2024-03-16T23:17:06.969987Z"
    }
   },
   "outputs": [],
   "source": [
    "# frequência: quantidade de compras / diferença entre datas\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply(lambda x: x['buy_']/x['days_'] if x['days_'] != 0 else 0, axis = 1)\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'frequency']], on = 'customer_id', how = 'left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c9f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.309253Z",
     "start_time": "2024-03-16T23:17:07.155276Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantidade de compras únicas e quantidade total de produtos por cliente\n",
    "df_aux = df2[['customer_id', 'invoice_no', 'quantity']].groupby('customer_id')\n",
    "df_aux = df_aux.agg(n_purchases = ('invoice_no', 'nunique'), n_products = ('quantity', 'sum')).reset_index()\n",
    "\n",
    "# average basket size: quantidade total de produtos por cliente / quantidade de compras únicas\n",
    "df_aux['basket_size'] = df_aux['n_products']/df_aux['n_purchases']\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'basket_size']], how = 'left', on = 'customer_id')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0991c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.339254Z",
     "start_time": "2024-03-16T23:17:07.312255Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1515b5",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27827e0f",
   "metadata": {},
   "source": [
    "## 4.1 Univariate and Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d574d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.433179Z",
     "start_time": "2024-03-16T23:17:07.342254Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df_ref.dropna()\n",
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8071b",
   "metadata": {},
   "source": [
    "# 5.0 Data Preparation and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e87e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T18:50:33.889489Z",
     "start_time": "2024-01-17T18:50:33.876510Z"
    }
   },
   "source": [
    "## 5.1 Feature Selection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d88245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.526173Z",
     "start_time": "2024-03-16T23:17:07.436123Z"
    }
   },
   "outputs": [],
   "source": [
    "# selecionando as features para o estudo do espaço de dados\n",
    "cols_selected = ['customer_id','gross_revenue','recency_days','frequency','qt_invoices',\n",
    "                 'qt_products','qt_items','qt_returns','basket_size','avg_ticket']\n",
    "df42 = df4[cols_selected].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c89f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.679877Z",
     "start_time": "2024-03-16T23:17:07.529136Z"
    }
   },
   "outputs": [],
   "source": [
    "# reescala dos dados para poder realizar o estudo\n",
    "mm = pp.MinMaxScaler()\n",
    "\n",
    "# distribuição não normal\n",
    "df42['gross_revenue'] = mm.fit_transform(df42[['gross_revenue']] )\n",
    "df42['recency_days'] = mm.fit_transform(df42[['recency_days']] )\n",
    "df42['qt_invoices'] = mm.fit_transform(df42[['qt_invoices']])\n",
    "df42['qt_products'] = mm.fit_transform(df42[['qt_products']])\n",
    "df42['qt_items'] = mm.fit_transform(df42[['qt_items']])\n",
    "df42['avg_ticket'] = mm.fit_transform(df42[['avg_ticket']])\n",
    "df42['frequency'] = mm.fit_transform(df42[['frequency']])\n",
    "df42['qt_returns'] = mm.fit_transform(df42[['qt_returns']])\n",
    "df42['basket_size'] = mm.fit_transform(df42[['basket_size']])\n",
    "\n",
    "X = df42.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9aa52",
   "metadata": {},
   "source": [
    "## 5.2 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f8051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:07.758586Z",
     "start_time": "2024-03-16T23:17:07.682820Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pca = X.drop(['customer_id'], axis = 1)\n",
    "pca = dd.PCA(n_components = X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2410d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:08.115664Z",
     "start_time": "2024-03-16T23:17:07.760569Z"
    }
   },
   "outputs": [],
   "source": [
    "principal_components = pca.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8a182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:08.131663Z",
     "start_time": "2024-03-16T23:17:08.118663Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6 features\n",
    "features = range(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1a0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:08.302566Z",
     "start_time": "2024-03-16T23:17:08.134664Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f1ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:08.427661Z",
     "start_time": "2024-03-16T23:17:08.305567Z"
    }
   },
   "outputs": [],
   "source": [
    "# o componente 0 é referente à primeira feature selecionada anteriormente (gross_revenue)\n",
    "# quanto maior a variação do eixo y, mais a variável ajuda a selecionar os clusters\n",
    "# com o PCA não é possível visualizar com clareza os clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68349a9",
   "metadata": {},
   "source": [
    "## 5.4 t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd938312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:17:38.247610Z",
     "start_time": "2024-03-16T23:17:08.430673Z"
    }
   },
   "outputs": [],
   "source": [
    "# redutor de dimensionalidade, funciona semelhante ao UMAP\n",
    "reducer = mn.TSNE(n_components = 2, n_jobs = -1, random_state = 42)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "df_pca['embedding_x'] = embedding[:, 0]\n",
    "df_pca['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'embedding_x', y = 'embedding_y', data = df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e51709",
   "metadata": {},
   "source": [
    "## 5.5 Tree-Based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf1628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:18:31.237712Z",
     "start_time": "2024-03-16T23:17:38.250612Z"
    }
   },
   "outputs": [],
   "source": [
    "# escolhendo a variável gross_revenue como label, pois para construir um grupo de clientes fiéis\n",
    "# uma das principais características desejadas é que este grupo gaste mais\n",
    "X_tree = df42.drop(columns = ['customer_id', 'gross_revenue'], axis = 1)\n",
    "y_tree = df42['gross_revenue']\n",
    "\n",
    "rf_model = en.RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_model.fit(X_tree, y_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6df921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:18:32.609711Z",
     "start_time": "2024-03-16T23:18:31.241713Z"
    }
   },
   "outputs": [],
   "source": [
    "# shape que tem como quantidade de linhas os clientes (cada linha é um cliente) e como colunas os estimators\n",
    "# cada par de linha-coluna indica em qual posição o cliente daquela linha caiu naquela árvore\n",
    "# Se as posições são próximas ao longo das árvores, significa que provavelmente aquele cliente está bem clusterizado\n",
    "df_leaf = pd.DataFrame(rf_model.apply(X_tree))\n",
    "df_leaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31347ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:49.846530Z",
     "start_time": "2024-03-16T23:18:32.613711Z"
    }
   },
   "outputs": [],
   "source": [
    "# redutor de dimensionalidade UMAP sobre o espaço criado pela Random Forest\n",
    "reducer = umap.UMAP(random_state = 42, n_components = 3)\n",
    "embedding = reducer.fit_transform(df_leaf)\n",
    "\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]\n",
    "df_tree['embedding_z'] = embedding[:, 2]\n",
    "\n",
    "# sns.scatterplot(x = 'embedding_x', y = 'embedding_y', data = df_tree)\n",
    "fig = px.scatter_3d(df_tree, x = 'embedding_x', y = 'embedding_y', z = 'embedding_z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c7e13-9d08-4d04-a459-387b4b09760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # passando o dataframe do embedding para um csv\n",
    "# df_tree.to_csv('tree_based_embedding.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b0144",
   "metadata": {},
   "source": [
    "# 6.0 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e84614",
   "metadata": {},
   "source": [
    "## 6.1 Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e7e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:49.861507Z",
     "start_time": "2024-03-16T23:19:49.850509Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_tsne = df_pca[['embedding_x', 'embedding_y']]\n",
    "# df_tsne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6578af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:50.049508Z",
     "start_time": "2024-03-16T23:19:49.864510Z"
    }
   },
   "outputs": [],
   "source": [
    "# como os dados já foram reorganizados pelos embeddings da etapa anterior\n",
    "# não é necessária uma nova preparação dos dados\n",
    "# X = X.copy() # opção 1: clusterizar em cima do conjunto original (espaço de features)\n",
    "# X = df_tsne.copy() # opção 2: clusterizar em cima do embedding criado pelo t-sne\n",
    "X = df_tree.copy() # opção 3: clusterizar em cima do embedding criado pela random forest\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e888357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:50.205508Z",
     "start_time": "2024-03-16T23:19:50.052508Z"
    }
   },
   "outputs": [],
   "source": [
    "# fine tuning da quantidade de clusters\n",
    "clusters = np.arange(5, 13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579851a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:50.314510Z",
     "start_time": "2024-03-16T23:19:50.208509Z"
    }
   },
   "outputs": [],
   "source": [
    "# checando se há valores do tipo None\n",
    "none_check = X.applymap(lambda x: x is None)\n",
    "print(none_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2c39d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:50.438511Z",
     "start_time": "2024-03-16T23:19:50.318510Z"
    }
   },
   "outputs": [],
   "source": [
    "none_check.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a6950",
   "metadata": {},
   "source": [
    "## 6.2 K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b2a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.363618Z",
     "start_time": "2024-03-16T23:19:50.444510Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_list = []\n",
    "\n",
    "for k in clusters:\n",
    "    \n",
    "    kmeans_model = c.KMeans(n_clusters = k, random_state = 42)\n",
    "    kmeans_model.fit(X)\n",
    "    \n",
    "    labels = kmeans_model.predict(X)\n",
    "\n",
    "    sil = m.silhouette_score(X, labels, metric = 'euclidean')\n",
    "    kmeans_list.append(sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f118ac00-2bcd-437e-a375-c0fb03ffe159",
   "metadata": {},
   "source": [
    "## 6.8 Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bcf0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.366616Z",
     "start_time": "2024-03-16T23:19:52.366616Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 11\n",
    "\n",
    "kmeans_model = c.KMeans(n_clusters = k, random_state = 42) # se usar o parâmetro n_init = 300 os clusters se repetem\n",
    "kmeans_model.fit(X)\n",
    "    \n",
    "labels = kmeans_model.predict(X)\n",
    "\n",
    "print('SS value: {}'.format(m.silhouette_score(X, labels, metric = 'euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f51c0b3-d82f-41ce-8c9c-315693fe72e3",
   "metadata": {},
   "source": [
    "# 7.0 Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4deb3-36b3-4c6e-86c0-fe01388b2e1c",
   "metadata": {},
   "source": [
    "## 7.1 Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4a3e6-da13-4e6f-864c-dae75013c7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.369617Z",
     "start_time": "2024-03-16T23:19:52.369617Z"
    }
   },
   "outputs": [],
   "source": [
    "df7 = X.copy()\n",
    "df7['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e6bac-5a29-4122-a0ae-316e9044647c",
   "metadata": {},
   "source": [
    "## 7.2 Clusters Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c5a93-73a4-46a1-90e5-e86976bda600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.373619Z",
     "start_time": "2024-03-16T23:19:52.373619Z"
    }
   },
   "outputs": [],
   "source": [
    "df72 = df4[cols_selected].copy()\n",
    "df72['cluster'] = labels\n",
    "df72.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4a9e8-aeae-4c93-9ba3-1fd9930b12f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.375620Z",
     "start_time": "2024-03-16T23:19:52.375620Z"
    }
   },
   "outputs": [],
   "source": [
    "# percentual de clientes no cluster\n",
    "df_cluster = df72[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['perc_customer'] = 100*(df_cluster['customer_id']/df_cluster['customer_id'].sum())\n",
    "\n",
    "# avg gross revenue\n",
    "df_avg_gross_revenue = df72[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_gross_revenue, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg recency days\n",
    "df72['recency_days'] = df72['recency_days'].apply(lambda x: 1/x if x != 1 else 0)\n",
    "df_avg_recency_days = df72[['recency_days', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_recency_days, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg frequency\n",
    "df_frequency = df72[['frequency', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_frequency, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg invoices\n",
    "df_qt_invoices = df72[['qt_invoices', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_qt_invoices, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg items\n",
    "df_qt_items = df72[['qt_items', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_qt_items, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg products\n",
    "df_qt_products = df72[['qt_products', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_qt_products, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg returns\n",
    "df_qt_returns = df72[['qt_returns', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_qt_returns, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg basket size\n",
    "df_basket_size = df72[['basket_size', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_basket_size, how = 'inner', on = 'cluster')\n",
    "\n",
    "# avg ticket\n",
    "df_avg_ticket = df72[['avg_ticket', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, how = 'inner', on = 'cluster')\n",
    "\n",
    "df_cluster.sort_values('gross_revenue', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbef3d0-8efc-45e7-8def-3633eae5133e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.377618Z",
     "start_time": "2024-03-16T23:19:52.377618Z"
    }
   },
   "outputs": [],
   "source": [
    "# teste t-student para gerar intervalos de confiança (variação dos valores médios do gross_revenue)\n",
    "# pode servir como critério estatístico para eleger ou remover um cliente do Insiders\n",
    "df_insiders = df72.loc[df72['cluster'] == 5, 'gross_revenue']\n",
    "\n",
    "# df: degrees of freedom (graus de liberdade)\n",
    "st.t.interval(confidence = 0.95, df = len(df_insiders)-1, loc = np.mean(df_insiders), scale = st.sem(df_insiders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2eddb6",
   "metadata": {},
   "source": [
    "## 8.2 Insiders Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc03aa-dcf4-4e6d-b677-be2b0d04bd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.379619Z",
     "start_time": "2024-03-16T23:19:52.379619Z"
    }
   },
   "outputs": [],
   "source": [
    "df82 = df72[df72['cluster'] == 5]['customer_id']\n",
    "df82.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b739a9-3607-4b90-b019-1ba0cfa81094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:19:52.383620Z",
     "start_time": "2024-03-16T23:19:52.383620Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Exportando conjunto csv\n",
    "# df82.to_csv('insiders.csv', header = 'customer_id', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16e6bd-423c-4635-808f-894e0e552475",
   "metadata": {},
   "source": [
    "# 9.0 Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323c5ef-8c74-4854-80a4-3baf5894e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df72.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71dce9f-8ecb-485e-a9d5-a1e0ddc9b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conectando ao sqlite\n",
    "# host = 'sqlite:///insiders_db.sqlite'\n",
    "\n",
    "# conectando ao postgres RDS AWS:\n",
    "host = 'db-insiders.cvik2cisqfe9.us-east-1.rds.amazonaws.com'\n",
    "port = '5432'\n",
    "database = 'db-insiders'\n",
    "user = 'postgres'\n",
    "pwd = 'insidersPA005'\n",
    "\n",
    "endpoint = 'postgresql://postgres:insidersPA005@db-insiders.cvik2cisqfe9.us-east-1.rds.amazonaws.com/postgres:5432'\n",
    "\n",
    "conn = create_engine(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b471fa-ac54-41c4-aed0-3c0b18623649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop table (caso já exista uma tabela)\n",
    "# query_drop_insiders = \"\"\"\n",
    "#     DROP TABLE insiders\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32802bab-323c-4b5a-8d37-13dbd06b0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação da tabela (rodar só uma vez)\n",
    "query_create_table_insiders = \"\"\"\n",
    "    CREATE TABLE insiders (\n",
    "        customer_id   INTEGER,\n",
    "        gross_revenue REAL,\n",
    "        recency_days  INTEGER,\n",
    "        frequency     INTEGER,\n",
    "        qt_invoices   INTEGER,\n",
    "        qt_products   INTEGER,\n",
    "        qt_items      INTEGER,\n",
    "        qt_returns    INTEGER,\n",
    "        basket_size   INTEGER,\n",
    "        avg_ticket    INTEGER,\n",
    "        cluster       INTEGER)\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(query_create_table_insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262fa87-a1fc-4e43-891a-b920717c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dropar a tabela caso já exista\n",
    "# conn.execute(query_drop_insiders)\n",
    "# conn.commit()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d1a0c-eb55-486f-8855-15eef6de618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserindo os dados na tabela criada\n",
    "df72.to_sql('insiders', con = conn, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75e884-7d63-459b-a2d8-2265140ff6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trazendo os dados\n",
    "query = \"\"\"\n",
    "    SELECT * FROM insiders\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82821f-cb9f-4fcf-9300-3c021807e51b",
   "metadata": {},
   "source": [
    "# 10. Saving Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6e801-2217-4024-a2a2-04e5fe7a6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features local\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
